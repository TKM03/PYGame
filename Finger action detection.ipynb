{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85bbc917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized letter: I\n",
      "Try again!\n",
      "Recognized letter: A\n",
      "Try again!\n",
      "Recognized letter: O\n",
      "Correct! Task completed.\n",
      "Recognized letter: I\n",
      "Try again!\n",
      "Recognized letter: N\n",
      "Try again!\n",
      "Recognized letter: T\n",
      "Try again!\n",
      "Recognized letter: L\n",
      "Try again!\n",
      "Recognized letter: \n",
      "Try again!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from scipy.interpolate import splprep, splev\n",
    "import re  # For regular expression matching\n",
    "\n",
    "# Set up pytesseract (specify the path to tesseract executable if necessary)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "class Sprite:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.size = 1\n",
    "        self.visible = False\n",
    "        self.path_points = []\n",
    "        self.max_points = 200  # Reduced number of points for simpler drawing\n",
    "\n",
    "    def setx(self, x):\n",
    "        self.x = int(x)\n",
    "\n",
    "    def sety(self, y):\n",
    "        self.y = int(y)\n",
    "\n",
    "    def show(self):\n",
    "        self.visible = True\n",
    "\n",
    "    def hide(self):\n",
    "        self.visible = False\n",
    "\n",
    "    def draw_path(self, frame, thickness=5):\n",
    "        if len(self.path_points) > 1:\n",
    "            smoothed_path = self.smooth_path(self.path_points)\n",
    "            for i in range(1, len(smoothed_path)):\n",
    "                cv2.line(frame, smoothed_path[i - 1], smoothed_path[i], (255, 255, 255), thickness)\n",
    "\n",
    "    def add_point(self):\n",
    "        if not self.path_points or np.linalg.norm(np.array([self.x, self.y]) - np.array(self.path_points[-1])) > 10:  # Increased threshold\n",
    "            self.path_points.append((self.x, self.y))\n",
    "            if len(self.path_points) > self.max_points:\n",
    "                self.path_points.pop(0)\n",
    "\n",
    "    def clear_path(self):\n",
    "        self.path_points = []\n",
    "\n",
    "    def smooth_path(self, path_points):\n",
    "        if len(path_points) < 2:\n",
    "            return path_points\n",
    "        \n",
    "        # Convert path points to numpy array\n",
    "        path_points = np.array(path_points)\n",
    "        \n",
    "        # If there are not enough points for spline interpolation, use linear interpolation\n",
    "        if len(path_points) < 8:\n",
    "            return path_points.tolist()\n",
    "\n",
    "        # Fit spline to the path points\n",
    "        tck, u = splprep([path_points[:, 0], path_points[:, 1]], s=0, k=3)\n",
    "        \n",
    "        # Generate smooth points along the spline\n",
    "        u_fine = np.linspace(0, 1, num=len(path_points)*10)  # Increase number of points for smoothness\n",
    "        new_points = splev(u_fine, tck)\n",
    "        smoothed_path = list(zip(map(int, new_points[0]), map(int, new_points[1])))\n",
    "        \n",
    "        return smoothed_path\n",
    "\n",
    "def preprocess_image(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image = cv2.GaussianBlur(gray_image, (5, 5), 0)  # Increased blur for smoother edges\n",
    "    binary_image = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    return binary_image\n",
    "\n",
    "def get_next_task():\n",
    "    # For simplicity, return a fixed task or shape name\n",
    "    return 'O'  # Example task, you can implement more complex task logic\n",
    "\n",
    "def filter_alphabetical(text):\n",
    "    # Keep only alphabetical characters and return as uppercase\n",
    "    return ''.join(re.findall(r'[A-Za-z]', text)).upper()\n",
    "\n",
    "# Create Sprite object for drawing\n",
    "index_finger = Sprite('IndexFinger')\n",
    "\n",
    "# Initialize MediaPipe for hand tracking\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize game state\n",
    "current_task = get_next_task()\n",
    "task_complete = False\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize frame for faster processing\n",
    "        small_frame = cv2.resize(frame, (640, 480))\n",
    "        frame = cv2.flip(small_frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb_frame)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            for hand_landmarks in result.multi_hand_landmarks:\n",
    "                index_pos = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "                index_finger.setx(index_pos.x * frame.shape[1])\n",
    "                index_finger.sety(index_pos.y * frame.shape[0])\n",
    "                index_finger.show()\n",
    "                index_finger.add_point()\n",
    "                index_finger.draw_path(frame)\n",
    "\n",
    "        else:\n",
    "            index_finger.hide()\n",
    "\n",
    "        cv2.imshow('Hand Tracking with Drawing', frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            index_finger.clear_path()\n",
    "        elif key == ord('r'):\n",
    "            if len(index_finger.path_points) > 1:\n",
    "                blank_image = np.zeros((frame.shape[0], frame.shape[1], 3), np.uint8)\n",
    "                index_finger.draw_path(blank_image, thickness=10)\n",
    "                processed_image = preprocess_image(blank_image)\n",
    "                text = pytesseract.image_to_string(processed_image, config='--psm 10')\n",
    "                recognized_text = filter_alphabetical(text)  # Filter to alphabetical characters\n",
    "                print(f'Recognized letter: {recognized_text}')\n",
    "\n",
    "                if recognized_text == current_task:\n",
    "                    print(\"Correct! Task completed.\")\n",
    "                    task_complete = True\n",
    "                else:\n",
    "                    print(\"Try again!\")\n",
    "\n",
    "        elif key == ord('n') or key == ord('N'):\n",
    "            if task_complete:\n",
    "                current_task = get_next_task()\n",
    "                print(f'New task: {current_task}')\n",
    "                index_finger.clear_path()\n",
    "                task_complete = False\n",
    "            else:\n",
    "                print(\"Complete the current task before moving to the next.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "141d6237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized letter: O\n",
      "Correct! Task completed.\n",
      "Recognized letter: O\n",
      "Correct! Task completed.\n",
      "Recognized letter: N\n",
      "Try again!\n",
      "Recognized letter: AN\n",
      "Try again!\n",
      "Recognized letter: A\n",
      "Try again!\n",
      "Recognized letter: T\n",
      "Try again!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from scipy.interpolate import splprep, splev\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Set up pytesseract (specify the path to tesseract executable if necessary)\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "class Sprite:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.x = 0\n",
    "        self.y = 0\n",
    "        self.size = 1\n",
    "        self.visible = False\n",
    "        self.path_points = []\n",
    "        self.max_points = 200  # Reduced number of points for simpler drawing\n",
    "\n",
    "    def setx(self, x):\n",
    "        self.x = int(x)\n",
    "\n",
    "    def sety(self, y):\n",
    "        self.y = int(y)\n",
    "\n",
    "    def show(self):\n",
    "        self.visible = True\n",
    "\n",
    "    def hide(self):\n",
    "        self.visible = False\n",
    "\n",
    "    def draw_path(self, frame, thickness=5):\n",
    "        if len(self.path_points) > 1:\n",
    "            smoothed_path = self.smooth_path(self.path_points)\n",
    "            for i in range(1, len(smoothed_path)):\n",
    "                cv2.line(frame, smoothed_path[i - 1], smoothed_path[i], (255, 255, 255), thickness)\n",
    "\n",
    "    def add_point(self):\n",
    "        if not self.path_points or np.linalg.norm(np.array([self.x, self.y]) - np.array(self.path_points[-1])) > 10:  # Increased threshold\n",
    "            self.path_points.append((self.x, self.y))\n",
    "            if len(self.path_points) > self.max_points:\n",
    "                self.path_points.pop(0)\n",
    "\n",
    "    def clear_path(self):\n",
    "        self.path_points = []\n",
    "\n",
    "    def smooth_path(self, path_points):\n",
    "        if len(path_points) < 2:\n",
    "            return path_points\n",
    "        \n",
    "        # Convert path points to numpy array\n",
    "        path_points = np.array(path_points)\n",
    "        \n",
    "        # If there are not enough points for spline interpolation, use linear interpolation\n",
    "        if len(path_points) < 8:\n",
    "            return path_points.tolist()\n",
    "\n",
    "        # Fit spline to the path points\n",
    "        tck, u = splprep([path_points[:, 0], path_points[:, 1]], s=0, k=3)\n",
    "        \n",
    "        # Generate smooth points along the spline\n",
    "        u_fine = np.linspace(0, 1, num=len(path_points)*10)  # Increase number of points for smoothness\n",
    "        new_points = splev(u_fine, tck)\n",
    "        smoothed_path = list(zip(map(int, new_points[0]), map(int, new_points[1])))\n",
    "        \n",
    "        return smoothed_path\n",
    "\n",
    "def preprocess_image(image):\n",
    "    # Convert to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Perform morphological operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    closing = cv2.morphologyEx(opening, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    \n",
    "    # Dilate to connect components\n",
    "    dilation = cv2.dilate(closing, kernel, iterations=1)\n",
    "    \n",
    "    return dilation\n",
    "\n",
    "def recognize_text(image):\n",
    "    # Prepare multiple versions of the image\n",
    "    processed_image = preprocess_image(image)\n",
    "    inverted_image = cv2.bitwise_not(processed_image)\n",
    "    \n",
    "    # Recognize text with different PSM modes and image versions\n",
    "    configs = [\n",
    "        '--psm 10 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
    "        '--psm 8 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
    "        '--psm 6 --oem 3 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    for config in configs:\n",
    "        results.append(pytesseract.image_to_string(processed_image, config=config).strip())\n",
    "        results.append(pytesseract.image_to_string(inverted_image, config=config).strip())\n",
    "    \n",
    "    # Post-process results\n",
    "    filtered_results = [filter_alphabetical(text) for text in results if text]\n",
    "    \n",
    "    # Choose the most common result, or the first one if there's no consensus\n",
    "    if filtered_results:\n",
    "        return Counter(filtered_results).most_common(1)[0][0]\n",
    "    return ''\n",
    "\n",
    "def filter_alphabetical(text):\n",
    "    # Keep only alphabetical characters and return as uppercase\n",
    "    return ''.join(re.findall(r'[A-Za-z]', text)).upper()\n",
    "\n",
    "def get_next_task():\n",
    "    # For simplicity, return a fixed task or shape name\n",
    "    return 'O'  # Example task, you can implement more complex task logic\n",
    "\n",
    "def overlay_text(frame, text, position=(50, 50), font_scale=2, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"Overlay text on the frame.\"\"\"\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, text, position, font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "# Create Sprite object for drawing\n",
    "index_finger = Sprite('IndexFinger')\n",
    "\n",
    "# Initialize MediaPipe for hand tracking\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize game state\n",
    "current_task = get_next_task()\n",
    "task_complete = False\n",
    "recognized_text = ''\n",
    "\n",
    "# Create full screen window\n",
    "cv2.namedWindow('Hand Tracking with Drawing', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Hand Tracking with Drawing', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "try:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize frame for faster processing\n",
    "        small_frame = cv2.resize(frame, (640, 480))\n",
    "        frame = cv2.flip(small_frame, 1)\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        result = hands.process(rgb_frame)\n",
    "\n",
    "        if result.multi_hand_landmarks:\n",
    "            # Process the first detected hand (assumes only one hand is tracked)\n",
    "            hand_landmarks = result.multi_hand_landmarks[0]\n",
    "            index_pos = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            index_finger.setx(index_pos.x * frame.shape[1])\n",
    "            index_finger.sety(index_pos.y * frame.shape[0])\n",
    "            index_finger.show()\n",
    "            index_finger.add_point()\n",
    "            index_finger.draw_path(frame)\n",
    "\n",
    "        else:\n",
    "            index_finger.hide()\n",
    "\n",
    "        # Display the frame with a dark background\n",
    "        dark_frame = np.zeros_like(frame)\n",
    "        index_finger.draw_path(dark_frame, thickness=10)\n",
    "        \n",
    "        # Display recognized text and current task\n",
    "        if recognized_text:\n",
    "            overlay_text(dark_frame, f\"Recognized: {recognized_text}\", position=(50, 50))\n",
    "        overlay_text(dark_frame, f\"Current Task: {current_task}\", position=(50, 100))\n",
    "\n",
    "        cv2.imshow('Hand Tracking with Drawing', dark_frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('c'):\n",
    "            index_finger.clear_path()\n",
    "            recognized_text = ''  # Clear recognized text when path is cleared\n",
    "        elif key == ord('r'):\n",
    "            if len(index_finger.path_points) > 1:\n",
    "                blank_image = np.zeros((frame.shape[0], frame.shape[1], 3), np.uint8)\n",
    "                index_finger.draw_path(blank_image, thickness=10)\n",
    "                recognized_text = recognize_text(blank_image)\n",
    "                \n",
    "                print(f'Recognized letter: {recognized_text}')\n",
    "\n",
    "                if recognized_text == current_task:\n",
    "                    print(\"Correct! Task completed.\")\n",
    "                    task_complete = True\n",
    "                else:\n",
    "                    print(\"Try again!\")\n",
    "\n",
    "        elif key == ord('n') or key == ord('N'):\n",
    "            if task_complete:\n",
    "                current_task = get_next_task()\n",
    "                print(f'New task: {current_task}')\n",
    "                index_finger.clear_path()\n",
    "                task_complete = False\n",
    "                recognized_text = ''  # Clear recognized text when moving to the next task\n",
    "            else:\n",
    "                print(\"Complete the current task before moving to the next.\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5c26ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
